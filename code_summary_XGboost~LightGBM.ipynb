{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88229a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전준비\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# xgboost\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "features = dataset.data\n",
    "labels = dataset.target\n",
    "\n",
    "cancer_df = pd.DataFrame(data=features, index=dataset.feature_names)\n",
    "cancer_df['target'] = labels\n",
    "\n",
    "\n",
    "X_features = cancer_df.iloc[:, :-1]\n",
    "y_label = cancer_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1624690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# XGBoost python native\n",
    "#################################################\n",
    "\n",
    "# 1.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_label, \n",
    "                                                    test_size=.2, random_state=156)\n",
    "# 2. 검증용 데이터 셋 (eval_set)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, \n",
    "                                            test_size=.1, random_state=156)\n",
    "\n",
    "# 3. 학습 (&검증)과 테스트 데이터셋을 DMatrix로 변환\n",
    "dtr = xgb.DMatrix(data=X_tr, label=y_tr)\n",
    "dval = xgb.DMatrix(data=X_val, label=y_val)\n",
    "dtest = xgb.DMatrix(data=X_test, label=y_test)\n",
    "\n",
    "# 4. 하이퍼 파라미터 설정\n",
    "params = {\n",
    "    'max_depth':3,\n",
    "    'eta':0.05, # learning_rate in sklearn\n",
    "    'objective':'binary:logistic',\n",
    "    'eval_metric':'logloss' # loss를 log화 시켜줌\n",
    "}\n",
    "num_rounds = 400 # n_estimators in sklearn\n",
    "\n",
    "# 5. 모델학습\n",
    "eval_list = [(dtr,'train'), (dval, 'eval')]\n",
    "xgb_model = xgb.train(params=params, dtrain=dtr,\n",
    "                      num_boost_rounds=num_rounds, # n_estimators in sklearn\n",
    "                      early_stopping_rounds=50-, # 더 이상 반복하지 말고 멈춰라\n",
    "                      evals=eval_list # 검증 데이터 셋\n",
    "                      )\n",
    "\n",
    "# 6. 결괏값\n",
    "# 1일 경우의 '확률'만 반환\n",
    "pred_probs = xgb_model.predict(dtest)\n",
    "# 1과 0의 결괏값으로 반환\n",
    "preds = [1 if x > 0.5 else 0 for x in pred_probs]\n",
    "\n",
    "get_clf_eval(y_test, preds, pred_probs)\n",
    "\n",
    "# 7. plot_importance\n",
    "import matplotlib.pyplot as plot\n",
    "%matplotlib inline\n",
    "\n",
    "# feature_importance는 f1 score을 기반으로 정해짐\n",
    "fig, ax = plt.subplots(figsize=(10,12))\n",
    "plot_importance(xgb_model, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9f9345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# XGBoost sklearn\n",
    "#################################################\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_label, \n",
    "                                                    test_size=.2, random_state=156)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train,\n",
    "                                            test_size=.1, random_state=156)\n",
    "evals=[(X_tr, y_tr), (X_val, y_val)]\n",
    "xgb_wrapper = XGBClassifier(n_estimators=400, learning_rate=.05, max_depth=3)\n",
    "                            # early stopping은 모델이 학습할 때 적용하므로 fit에 넣음\n",
    "xgb_wrapper.fit(X_tr, y_tr, early_stopping_rounds=50, \\\n",
    "                eval_metric='logloss', eval_set = evals, verbose=True)\n",
    "ws50_preds = xgb_wrapper.predict(X_test)\n",
    "ws50_pred_proba = xgb_wrapper.predict_proba(X_test)[:,1]\n",
    "\n",
    "# plot_importance\n",
    "fig, ax = subplots(figsize=(10,12))\n",
    "plot_importance(xgb_wrapper, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880418a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# lightGBM sklearn\n",
    "#################################################\n",
    "\n",
    "# 사실상 classifier만 바뀐 수준\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_label, \n",
    "                                                    test_size=.2, random_state=156)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train,\n",
    "                                            test_size=.1, random_state=156)\n",
    "evals=[(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_wrapper = LGBMClassifier(n_estimators=400, leanring_rate=.05)\n",
    "# 조기중단 가능\n",
    "lgbm_wrapper.fit(X_tr, y_tr, early_stopping_rounds=50,\n",
    "                 eval_metric='logloss', eval_set=evals, verbose=True)\n",
    "preds = lgbm_wrapper.predict(X_test)\n",
    "pred_proba = lgbm_wrapper.predict_proba(X_test)[:,1]\n",
    "\n",
    "# get_clf_eval\n",
    "get_clf_eval(y_test, preds, pred_proba)\n",
    "\n",
    "# plot_importance\n",
    "from lightgbm import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.figure(figsize=(10,12))\n",
    "plot_importance(lgbm_wrapper, ax=ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
